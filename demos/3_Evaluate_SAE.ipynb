{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df783e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853798d6",
   "metadata": {},
   "source": [
    "# Evaluate vision SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33387114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nw/home/m.yu/repos/ViT-Prisma/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/nw/home/m.yu/repos/ViT-Prisma/.venv/lib/python3.13/site-packages/kaleido/_sync_server.py:11: UserWarning:\n",
      "\n",
      "\n",
      "\n",
      "Warning: You have Plotly version 5.19.0, which is not compatible with this version of Kaleido (1.2.0).\n",
      "\n",
      "This means that static image generation (e.g. `fig.write_image()`) will not work.\n",
      "\n",
      "Please upgrade Plotly to version 6.1.1 or greater, or downgrade Kaleido to version 0.2.1.\n",
      "\n",
      "\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.connection: connect_tcp.started host='huggingface.co' port=443 local_address=None timeout=10 socket_options=None\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x724b55db2cf0>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x724bc97ded50> server_hostname='huggingface.co' timeout=10\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x724b55e0c410>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_headers.started request=<Request [b'HEAD']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_headers.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_body.started request=<Request [b'HEAD']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_body.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_headers.started request=<Request [b'HEAD']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 302, b'Found', [(b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'1329'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 16 Feb 2026 21:31:19 GMT'), (b'Location', b'https://cas-bridge.xethub.hf.co/xet-bridge-us/67250013b22109dd6c60f8cd/91cba7fd94485595f0bb7a3a9c3f3ad07fde84293b5d4ac927540886fdda4fa2?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260216%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260216T213119Z&X-Amz-Expires=3600&X-Amz-Signature=ffc1750ce946f21a15dd10fdb7020967e09a8d8d85d7bcd682ba30a052d63fa9&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=6455498b1f9406d48802f043&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27weights.pt%3B+filename%3D%22weights.pt%22%3B&x-id=GetObject&Expires=1771281079&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc3MTI4MTA3OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NzI1MDAxM2IyMjEwOWRkNmM2MGY4Y2QvOTFjYmE3ZmQ5NDQ4NTU5NWYwYmI3YTNhOWMzZjNhZDA3ZmRlODQyOTNiNWQ0YWM5Mjc1NDA4ODZmZGRhNGZhMioifV19&Signature=flNFvM-KWnd1D7kJHi%7ENIGqKioQipkRf77ajEIq5buTL3aV0%7EkS-vzdiazGVox8t8OAoGErsBEGUSD%7EzhzrmQm%7EUp8VjvyXEYogcztPpiqazuYCZXLOKjH7Owc5w6nvIQrQpIECNRxIBL3ZL0pMq4JsXOCpXXGYWzPwMThPDkOoRpQOIlQr9suDbSSoQao6kPvaC%7EFQGLTNszzhIFp3DLRwxFRcrIj7D1Cf6pseI8-kZMPVFQd1sGkzN8Bhv5DT5VQ1127bE4Z76KdwpEiaNLHMEh74%7EJbR6ImDB98HtJIbayIw%7Esuk7gYkClta1uBKdxEGR5WLRwGO-lWTLOjf2gg__&Key-Pair-Id=K2L8F4GPSG1IFC'), (b'X-Powered-By', b'huggingface-moon'), (b'X-Request-Id', b'Root=1-69938ca7-3ccde37721ee8b4a5f5ad07a;55deec84-dbf1-4b12-957d-912804e61c0d'), (b'RateLimit', b'\"resolvers\";r=4996;t=108'), (b'RateLimit-Policy', b'\"fixed window\";\"resolvers\";q=5000;w=300'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Access-Control-Max-Age', b'86400'), (b'Access-Control-Allow-Origin', b'https://huggingface.co'), (b'Vary', b'Origin, Accept'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Repo-Commit', b'1e0dcc98c63aed3ce28f0387027cf8df6784fef1'), (b'Accept-Ranges', b'bytes'), (b'X-Hub-Cache', b'MISS'), (b'X-Linked-Size', b'302191832'), (b'X-Linked-ETag', b'\"5e3a03ac0639e32b54425831515dc0d4e6acd87ad7002e6217ba190b5f79fdbd\"'), (b'X-Xet-Hash', b'91cba7fd94485595f0bb7a3a9c3f3ad07fde84293b5d4ac927540886fdda4fa2'), (b'Link', b'<https://huggingface.co/api/models/Prisma-Multimodal/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-1e-05/xet-read-token/1e0dcc98c63aed3ce28f0387027cf8df6784fef1>; rel=\"xet-auth\", <https://cas-server.xethub.hf.co/v1/reconstructions/91cba7fd94485595f0bb7a3a9c3f3ad07fde84293b5d4ac927540886fdda4fa2>; rel=\"xet-reconstruction-info\"'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 e2ef54be36cbd5bbe7d8d39b7e557398.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'YUL62-P3'), (b'X-Amz-Cf-Id', b'k11_G7TSjQ5vsugveO8A2muwhMtUIR60uYgmifKAke5OHatPA9NA3w==')])\n",
      "2026-02-16 21:31:19 INFO:httpx: HTTP Request: HEAD https://huggingface.co/Prisma-Multimodal/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-1e-05/resolve/main/weights.pt \"HTTP/1.1 302 Found\"\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_body.started request=<Request [b'HEAD']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_body.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: response_closed.started\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: response_closed.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_headers.started request=<Request [b'HEAD']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_headers.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_body.started request=<Request [b'HEAD']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_body.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_headers.started request=<Request [b'HEAD']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 307, b'Temporary Redirect', [(b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'390'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 16 Feb 2026 21:31:19 GMT'), (b'Location', b'/api/resolve-cache/models/Prisma-Multimodal/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-1e-05/1e0dcc98c63aed3ce28f0387027cf8df6784fef1/config.json?%2FPrisma-Multimodal%2Fsparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-1e-05%2Fresolve%2Fmain%2Fconfig.json=&etag=%22c6a1690ed0b81c9bcba593c9bfea2bbe711a7049%22'), (b'X-Powered-By', b'huggingface-moon'), (b'X-Request-Id', b'Root=1-69938ca7-52a8d4ea7f590cc236f07b28;92a34096-8ba2-43cf-9863-ced43b672281'), (b'RateLimit', b'\"resolvers\";r=4995;t=108'), (b'RateLimit-Policy', b'\"fixed window\";\"resolvers\";q=5000;w=300'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Access-Control-Max-Age', b'86400'), (b'Access-Control-Allow-Origin', b'https://huggingface.co'), (b'Vary', b'Origin, Accept'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Repo-Commit', b'1e0dcc98c63aed3ce28f0387027cf8df6784fef1'), (b'Accept-Ranges', b'bytes'), (b'X-Hub-Cache', b'MISS'), (b'Content-Disposition', b'inline; filename*=UTF-8\\'\\'config.json; filename=\"config.json\";'), (b'Content-Security-Policy', b\"default-src 'none'; sandbox\"), (b'X-Linked-ETag', b'\"c6a1690ed0b81c9bcba593c9bfea2bbe711a7049\"'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 e2ef54be36cbd5bbe7d8d39b7e557398.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'YUL62-P3'), (b'X-Amz-Cf-Id', b'E_3uL2XjwY2zhpSTe1b7q6JesOTotNqeatRbTKVU5jXlkhFTBBuE4Q==')])\n",
      "2026-02-16 21:31:19 INFO:httpx: HTTP Request: HEAD https://huggingface.co/Prisma-Multimodal/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-1e-05/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_body.started request=<Request [b'HEAD']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_body.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: response_closed.started\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: response_closed.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_headers.started request=<Request [b'HEAD']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_headers.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_body.started request=<Request [b'HEAD']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_body.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_headers.started request=<Request [b'HEAD']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'2251'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 16 Feb 2026 21:31:19 GMT'), (b'ETag', b'\"c6a1690ed0b81c9bcba593c9bfea2bbe711a7049\"'), (b'X-Powered-By', b'huggingface-moon'), (b'X-Request-Id', b'Root=1-69938ca7-012993b84d2a691861afbe3d;05735311-9615-498e-9012-d0e477150404'), (b'RateLimit', b'\"resolvers\";r=4994;t=108'), (b'RateLimit-Policy', b'\"fixed window\";\"resolvers\";q=5000;w=300'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Access-Control-Max-Age', b'86400'), (b'Access-Control-Allow-Origin', b'https://huggingface.co'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Repo-Commit', b'1e0dcc98c63aed3ce28f0387027cf8df6784fef1'), (b'Accept-Ranges', b'bytes'), (b'X-Hub-Cache', b'MISS'), (b'Content-Disposition', b'inline; filename*=UTF-8\\'\\'config.json; filename=\"config.json\";'), (b'Content-Security-Policy', b\"default-src 'none'; sandbox\"), (b'Vary', b'Origin'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 e2ef54be36cbd5bbe7d8d39b7e557398.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'YUL62-P3'), (b'X-Amz-Cf-Id', b'xBU466WQ9ZPBDsRBGWQb_w2Y4v-hFp2XviDb7XOFE6l8K6LxRMwAzg==')])\n",
      "2026-02-16 21:31:19 INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/Prisma-Multimodal/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-1e-05/1e0dcc98c63aed3ce28f0387027cf8df6784fef1/config.json \"HTTP/1.1 200 OK\"\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_body.started request=<Request [b'HEAD']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_body.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: response_closed.started\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: response_closed.complete\n",
      "2026-02-16 21:31:19 DEBUG:filelock: Attempting to acquire lock 125667888537888 on /mnt/nw/home/m.yu/.cache/huggingface/hub/.locks/models--Prisma-Multimodal--sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-1e-05/c6a1690ed0b81c9bcba593c9bfea2bbe711a7049.lock\n",
      "2026-02-16 21:31:19 DEBUG:filelock: Lock 125667888537888 acquired on /mnt/nw/home/m.yu/.cache/huggingface/hub/.locks/models--Prisma-Multimodal--sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-1e-05/c6a1690ed0b81c9bcba593c9bfea2bbe711a7049.lock\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_headers.started request=<Request [b'GET']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_headers.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_body.started request=<Request [b'GET']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: send_request_body.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_headers.started request=<Request [b'GET']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 16 Feb 2026 21:31:19 GMT'), (b'Content-Security-Policy', b\"default-src 'none'; sandbox\"), (b'Content-Disposition', b'inline; filename*=UTF-8\\'\\'config.json; filename=\"config.json\";'), (b'X-Powered-By', b'huggingface-moon'), (b'X-Request-Id', b'Root=1-69938ca7-666645b5210997280e14a89f;29839544-dc50-4a8f-976e-f71046b93c07'), (b'RateLimit', b'\"resolvers\";r=4993;t=108'), (b'RateLimit-Policy', b'\"fixed window\";\"resolvers\";q=5000;w=300'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'Access-Control-Max-Age', b'86400'), (b'Access-Control-Allow-Origin', b'https://huggingface.co'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Repo-Commit', b'1e0dcc98c63aed3ce28f0387027cf8df6784fef1'), (b'Content-Encoding', b'gzip'), (b'ETag', b'W/\"c6a1690ed0b81c9bcba593c9bfea2bbe711a7049\"'), (b'Vary', b'Origin,accept-encoding'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 e2ef54be36cbd5bbe7d8d39b7e557398.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'YUL62-P3'), (b'X-Amz-Cf-Id', b'jEjdzA3Gw-jR_UAbS0pf7OfSbkucqGtf7u9g1L7tnCMEvg9w2Zh4Jw==')])\n",
      "2026-02-16 21:31:19 INFO:httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/Prisma-Multimodal/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-1e-05/1e0dcc98c63aed3ce28f0387027cf8df6784fef1/config.json \"HTTP/1.1 200 OK\"\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_body.started request=<Request [b'GET']>\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: receive_response_body.complete\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: response_closed.started\n",
      "2026-02-16 21:31:19 DEBUG:httpcore.http11: response_closed.complete\n",
      "2026-02-16 21:31:19 DEBUG:filelock: Attempting to release lock 125667888537888 on /mnt/nw/home/m.yu/.cache/huggingface/hub/.locks/models--Prisma-Multimodal--sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-1e-05/c6a1690ed0b81c9bcba593c9bfea2bbe711a7049.lock\n",
      "2026-02-16 21:31:19 DEBUG:filelock: Lock 125667888537888 released on /mnt/nw/home/m.yu/.cache/huggingface/hub/.locks/models--Prisma-Multimodal--sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-1e-05/c6a1690ed0b81c9bcba593c9bfea2bbe711a7049.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAE from /mnt/nw/home/m.yu/.cache/huggingface/hub/models--Prisma-Multimodal--sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-1e-05/snapshots/1e0dcc98c63aed3ce28f0387027cf8df6784fef1/weights.pt...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Error loading the state dictionary from .pt file: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/ViT-Prisma/src/vit_prisma/sae/sae.py:446\u001b[39m, in \u001b[36mSparseAutoencoder.load_from_pretrained\u001b[39m\u001b[34m(cls, weights_path, current_cfg, config_path)\u001b[39m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m     state_dict = \u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/ViT-Prisma/src/vit_prisma/sae/sae.py:434\u001b[39m, in \u001b[36mSparseAutoencoder.load_from_pretrained.<locals>.load_weights\u001b[39m\u001b[34m(path, device)\u001b[39m\n\u001b[32m    433\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.load(path, map_location=device, weights_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/ViT-Prisma/.venv/lib/python3.13/site-packages/torch/serialization.py:1549\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1548\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1549\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1550\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/ViT-Prisma/.venv/lib/python3.13/site-packages/torch/serialization.py:2143\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2142\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2143\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2144\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/ViT-Prisma/.venv/lib/python3.13/site-packages/torch/serialization.py:2107\u001b[39m, in \u001b[36m_load.<locals>.persistent_load\u001b[39m\u001b[34m(saved_id)\u001b[39m\n\u001b[32m   2106\u001b[39m     nbytes = numel * torch._utils._element_size(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2107\u001b[39m     typed_storage = \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2109\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/ViT-Prisma/.venv/lib/python3.13/site-packages/torch/serialization.py:2073\u001b[39m, in \u001b[36m_load.<locals>.load_tensor\u001b[39m\u001b[34m(dtype, numel, key, location)\u001b[39m\n\u001b[32m   2072\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch._guards.detect_fake_mode(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2073\u001b[39m     wrap_storage = \u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2074\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/ViT-Prisma/.venv/lib/python3.13/site-packages/torch/serialization.py:707\u001b[39m, in \u001b[36mdefault_restore_location\u001b[39m\u001b[34m(storage, location)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/ViT-Prisma/.venv/lib/python3.13/site-packages/torch/serialization.py:640\u001b[39m, in \u001b[36m_deserialize\u001b[39m\u001b[34m(backend_name, obj, location)\u001b[39m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m location.startswith(backend_name):\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m     device = \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.to(device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/ViT-Prisma/.venv/lib/python3.13/site-packages/torch/serialization.py:609\u001b[39m, in \u001b[36m_validate_device\u001b[39m\u001b[34m(location, backend_name)\u001b[39m\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[33m\"\u001b[39m\u001b[33mis_available\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module.is_available():\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    610\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    611\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.is_available() is False. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    612\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf you are running on a CPU-only machine, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    613\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    614\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mto map your storages to the CPU.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    615\u001b[39m     )\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[33m\"\u001b[39m\u001b[33mdevice_count\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mRuntimeError\u001b[39m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m file_name = \u001b[33m\"\u001b[39m\u001b[33mweights.pt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# Usually weights.pt but may have slight naming variation. See the chosen HF repo for the exact file name\u001b[39;00m\n\u001b[32m     23\u001b[39m config_name = \u001b[33m\"\u001b[39m\u001b[33mconfig.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m sae = \u001b[43mload_sae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m sae.to(DEVICE)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mload_sae\u001b[39m\u001b[34m(repo_id, file_name, config_name)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Step 2: Now load the pretrained SAE weights from where you just downloaded them\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading SAE from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msae_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m sae = \u001b[43mSparseAutoencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43msae_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# This now automatically gets the config.json file in that folder and converts it into a VisionSAERunnerConfig object\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sae\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/ViT-Prisma/src/vit_prisma/sae/sae.py:448\u001b[39m, in \u001b[36mSparseAutoencoder.load_from_pretrained\u001b[39m\u001b[34m(cls, weights_path, current_cfg, config_path)\u001b[39m\n\u001b[32m    446\u001b[39m         state_dict = load_weights(weights_path, device)\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError loading the state dictionary from .pt file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m weights_path.endswith(\u001b[33m\"\u001b[39m\u001b[33m.pkl.gz\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    450\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mOSError\u001b[39m: Error loading the state dictionary from .pt file: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# Load SAE\n",
    "\n",
    "# Load an SAE\n",
    "from huggingface_hub import hf_hub_download, list_repo_files\n",
    "from vit_prisma.sae import SparseAutoencoder\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "def load_sae(repo_id, file_name, config_name):\n",
    "    # Step 1: Download SAE weights and SAE config from Hugginface\n",
    "    sae_path = hf_hub_download(repo_id, file_name) # Download SAE weights\n",
    "    hf_hub_download(repo_id, config_name) # Download SAE config\n",
    "\n",
    "    # Step 2: Now load the pretrained SAE weights from where you just downloaded them\n",
    "    print(f\"Loading SAE from {sae_path}...\")\n",
    "    sae = SparseAutoencoder.load_from_pretrained(sae_path) # This now automatically gets the config.json file in that folder and converts it into a VisionSAERunnerConfig object\n",
    "    return sae\n",
    "\n",
    "# Change the repo_id to the Huggingface repo of your chosen SAE. See /docs for a list of SAEs.\n",
    "repo_id = \"Prisma-Multimodal/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-1e-05\" \n",
    "file_name = \"weights.pt\" # Usually weights.pt but may have slight naming variation. See the chosen HF repo for the exact file name\n",
    "config_name = \"config.json\"\n",
    "\n",
    "sae = load_sae(repo_id, file_name, config_name)\n",
    "sae.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4eebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 23:27:15 INFO:root: Model 'open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K' is supported and passes tests.\n",
      "2025-06-01 23:27:15 INFO:root: model_id download_pretrained_from_hf: laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\n",
      "2025-06-01 23:27:15 DEBUG:urllib3.connectionpool: https://huggingface.co:443 \"HEAD /laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K/resolve/main/open_clip_config.json HTTP/1.1\" 200 0\n",
      "2025-06-01 23:27:15 INFO:root: model_id download_pretrained_from_hf: laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\n",
      "2025-06-01 23:27:15 DEBUG:urllib3.connectionpool: https://huggingface.co:443 \"HEAD /laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K/resolve/main/open_clip_pytorch_model.bin HTTP/1.1\" 302 0\n",
      "2025-06-01 23:27:16 INFO:root: visual projection shape: torch.Size([768, 512])\n",
      "2025-06-01 23:27:16 INFO:root: Loaded pretrained model open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HookedViT(\n",
       "  (embed): PatchEmbedding(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
       "  )\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbedding()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (hook_full_embed): HookPoint()\n",
       "  (ln_pre): LayerNorm(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (hook_ln_pre): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (ln1): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "      (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNorm(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (hook_ln_final): HookPoint()\n",
       "  (head): Head()\n",
       "  (hook_post_head_pre_normalize): HookPoint()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "from vit_prisma.models.model_loader import load_hooked_model\n",
    "\n",
    "\n",
    "model_name = sae.cfg.model_name\n",
    "model = load_hooked_model(model_name)\n",
    "model.to(DEVICE) # Move to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f9abd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 23:28:04 DEBUG:urllib3.connectionpool: https://huggingface.co:443 \"HEAD /laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K/resolve/main/open_clip_pytorch_model.bin HTTP/1.1\" 302 0\n",
      "2025-06-01 23:28:04 DEBUG:urllib3.connectionpool: https://huggingface.co:443 \"HEAD /laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K/resolve/main/open_clip_config.json HTTP/1.1\" 200 0\n",
      "2025-06-01 23:28:04 INFO:root: Loaded hf-hub:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K model config.\n",
      "2025-06-01 23:28:05 INFO:root: Loading pretrained hf-hub:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K weights (/home/mila/s/sonia.joseph/.cache/huggingface/hub/models--laion--CLIP-ViT-B-32-DataComp.XL-s13B-b90K/snapshots/f0e2ffa09cbadab3db6a261ec1ec56407ce42912/open_clip_pytorch_model.bin).\n",
      "2025-06-01 23:28:06 DEBUG:urllib3.connectionpool: https://huggingface.co:443 \"HEAD /laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K/resolve/main/open_clip_config.json HTTP/1.1\" 200 0\n",
      "2025-06-01 23:28:13 INFO:vit_prisma.sae.evals.model_eval: Starting SparseCoder evaluation...\n",
      "Evaluating: 100%|██████████| 250/250 [00:21<00:00, 11.87it/s, L0=2992.25, Cosine Sim=0.991065]\n",
      "2025-06-01 23:28:34 INFO:vit_prisma.sae.evals.model_eval: Finished running through validation dataset...\n",
      "2025-06-01 23:28:34 INFO:vit_prisma.sae.evals.model_eval: Computing metrics...\n",
      "2025-06-01 23:28:34 INFO:vit_prisma.sae.evals.model_eval: Average L0 (features activated): 777.640015\n",
      "2025-06-01 23:28:34 INFO:vit_prisma.sae.evals.model_eval: Average L0 (features activated) per CLS token: 893.646973\n",
      "2025-06-01 23:28:34 INFO:vit_prisma.sae.evals.model_eval: Average L0 (features activated) per image: 3047.367000\n",
      "2025-06-01 23:28:34 INFO:vit_prisma.sae.evals.model_eval: Average Cosine Similarity: 0.9915\n",
      "2025-06-01 23:28:34 INFO:vit_prisma.sae.evals.model_eval: Average Loss: 6.722949\n",
      "2025-06-01 23:28:34 INFO:vit_prisma.sae.evals.model_eval: Average Reconstruction Loss: 6.722559\n",
      "2025-06-01 23:28:34 INFO:vit_prisma.sae.evals.model_eval: Average Zero Ablation Loss: 6.740437\n",
      "2025-06-01 23:28:34 INFO:vit_prisma.sae.evals.model_eval: Average CE Score: nan\n",
      "2025-06-01 23:28:34 INFO:vit_prisma.sae.evals.model_eval: % CE recovered: 102.227793\n"
     ]
    }
   ],
   "source": [
    "# Evaluate vision SAE\n",
    "from vit_prisma.sae import SparsecoderEval\n",
    "from vit_prisma.transforms import get_clip_val_transforms\n",
    "\n",
    "import torchvision\n",
    "\n",
    "imagenet_validation_path = '/network/scratch/s/sonia.joseph/datasets/kaggle_datasets/ILSVRC/Data/CLS-LOC/val'\n",
    "\n",
    "data_transforms = get_clip_val_transforms()\n",
    "eval_dataset = torchvision.datasets.ImageFolder(imagenet_validation_path, transform=data_transforms)\n",
    "\n",
    "eval_runner = SparsecoderEval(sae, model, eval_dataset, max_images=1000)\n",
    "\n",
    "metrics = eval_runner.run_eval(is_clip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e474c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ViT-Prisma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
